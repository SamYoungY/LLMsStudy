# LANGUAGE AGENT TREE SEARCH UNIFIES REASON-ING ACTING AND PLANNING IN LANGUAGE MODELS

论文链接：https://arxiv.org/abs/2310.04406

GitHub：https://github.com/andyz245/LanguageAgentTreeSearch

## 1.论文背景

虽然大型语言模型 (LLM) 已经在多种多样的任务中表现出令人印象深刻的性能，以及展现出不俗的推理能力，但其在某些任务上表现得不尽如人意。目前的LLM的思维框架方法大都各自基于推理，基于动作，基于规划，却没有能一个能统筹各方面能力的框架。

## 2. 论文提出解决方案

论文提出一个LATS框架，协同了LLM在规划，行动，推理各方面的能力，并且能与外界环境进行交互得到外界的反馈，甚至加入了自我反思机制，让LLM代理能通过错误的推理轨迹进行一系列反思总结，学习到经验从而改善推理。

![](https://github.com/zzysos/LLMsStudy/blob/master/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/pic/LATS%E6%95%B4%E4%BD%93%E6%A1%86%E6%9E%B6.png)

## 3.论文方法

LLM Agent在推理过程中会不断迭代构建一个蒙特卡洛树结构，每次迭代都分为以下几个步骤：

![](https://github.com/zzysos/LLMsStudy/blob/master/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/pic/LATS%E8%BF%AD%E4%BB%A3%E8%BF%87%E7%A8%8B.png)

1.Selection：从根节点(表示为初始状态S0)开始，选择一个当前的叶节点进行扩展。为了平衡探索和开发，我们使用UCT算法来选择节点。

2.Expansion：在选择一个节点之后，第二个操作是通过Agent产生n个动作来扩展树。环境接收每个动作并返回相应的反馈（也叫观察）。这将导致向树中添加n个子节点。

3.Evaluation：通过一个评估器（一个带有特定提示的LLM）为新产生的每个节点分配一个评估值，用以评价该中间节点对之后完成目标任务的价值大小。

4.Simulation：经过评估器评估后，选出评价值最优的节点继续向下扩展，扩展方法同上，一直如此在每一层都进行这样的评估选择再扩展直至到达终端节点。若最终节点任务完成，则停止搜索并返回正确的推理路径。如果任务部分完成或未能完成，则视情况执行以下两个步骤。

5.Backpropagation：该操作根据轨迹的结果更新节点的value值。对于轨迹中的每个节点，其值被更新以反映模拟的结果。

6.Reflection：当遇到不成功的终端节点时，LLM会受到轨迹和最终奖励的提示，进行自我反思，总结推理或行动过程中的错误，并提出更好的替代方案。我们将失败的轨迹和相应的反思结果都存储在记忆中。在随后的迭代中，这些被集成为Agent和评估器的附加上下文，通过上下文学习对两者进行细化。

## 4. 实验分析

实验一：HotpotQA 

HotpotQA是一个大型问答数据集，这些问题的答案并不是现成的可以回答相应问题的形式，甚至这些答案都不集中在同一个地方。这些问题要求问答系统能够筛选大量的文本文档，以找到与生成答案相关的信息，并对找到的多个支撑性事实进行推理，从而得出最终答案。
实验会与维基百科进行交互，动作分为Search[entity]， lookup[keyword]， Finish[answer]。搜索返回的结果即为环境的反馈（观察）。

实验二：PROGRAMMING

用到HumanEval，MBPP数据集，任务是将一些自然语言描述的功能转化成对应语言的代码。会有多个测试点测试功能。
实验用测试工具和编译器的输出作为外部反馈。

实验三：WEBSHOP

这是一个在线购物环境，由一个拥有118万件真实产品和12k条人类指令的网站组成。代理必须通过各种命令浏览网站，以购买符合用户规格的物品。
实验使用预先构建的搜索和点击命令构建动作空间，浏览器的反馈内容来作为对环境的观察。



LATS框架在三个任务都表现良好，优于先前的其他方法。

## 5.论文总结

LATS融合了之前不少论文的思想，比如引入了RAP中所用的MCTS算法用作推理轨迹，又引入了ReAct中的action，observation等概念，使LLM能把与外界的交互也考虑进去，而后又引入了Reflexion的思想，让LLM能对错误的经历中进行反思学习以改进推理能力。有点像一个大杂烩，但确实有效果。

## 6.可能可以改进的点

作者认为LATS框架的计算成本较大，对资源的消耗也比较多，因此建议将LATS应用在一些比较复杂或结果质量要求较高而速度可以不做太多要求的任务中。
