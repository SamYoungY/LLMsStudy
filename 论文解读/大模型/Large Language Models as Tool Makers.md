# Large Language Models as Tool Makers

论文地址：https://arxiv.org/abs/2305.17126

论文代码：https://github.com/ctlllll/LLM-ToolMaker.

## 论文背景

作者认为在众多问题解决请求的情况下，直接利用强大的LLM来解决所有实例可能会导致高昂的成本。另一方面，轻量级模型具有成本效益，但通常难以处理复杂的任务。

作者认为LLM 可以创建他们自己的可重用的工具来解决问题。作者使用 GPT-4 作为工具制造商，GPT-3.5 作为工具用户

## 论文解决方案

作者提出的LATM 通过使用强大的模型作为工具制造商为请求中观察到的任务生成可重用的工具（实现为 Python 函数）来利用两种模型的优势，并将该工具传递给具有成本效益的工具用户模型，以解决以下请求中的类似实例。这种方法允许轻量级模型在保持更大的成本效率的同时，实现与强大模型相当的性能。

作者的方法包括两个关键阶段：

1）工具制作：LLM，称为工具制造商，专门为给定任务设计工具（实现为 Python 函数）。

2) 使用的工具：另一个 LLM 称为工具用户，可以与工具制造商相同，应用工具来处理新请求。两阶段设计允许LATM将每个阶段的作业分配到最合适的LLM。

具体来说，需要高度能力的工具制作过程可以分配给一个强大的、资源密集型的模型（例如 GPT-4）。另一方面，相对简单的工具使用过程可以分配给轻量级且具有成本效益的模型（例如 GPT-3.5 Turbo）。这种方法不仅增强了llm的问题解决能力，而且显著降低了解决一系列任务的平均计算成本。

在 LATM 范式中，主要过程可以分为两个阶段：工具制作和工具使用。每个阶段都利用不同类型的大型语言模型 (LLM) 来平衡性能和成本效益。

## LATM

![image-20240113100739586](https://raw.githubusercontent.com/XingYu-Zhong/LLMsStudy/master/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/pic/latm01.png)

有点像学霸闭卷考，学渣开卷考，但是学霸消耗的脑力更多，学渣开卷所以消耗的脑力相对没那么多。他的方法更像是学霸把做题技巧总结好，学渣拿着做题技巧去解题。

工具制作阶段可以进一步分为三个子阶段：

（i）提出工具：工具制造商尝试从一些训练演示中生成工具（Python 函数），如果工具不可执行，报告错误并生成一个新的（修复函数中的问题）； 

(ii) 工具验证：工具制造商在验证样本上运行单元测试，如果工具没有通过测试，报告错误并生成新的测试（修复单元测试中函数调用中的问题）；

 (iii) 工具包装：包装函数代码以及如何将问题转换为单元测试的函数调用的演示，为工具用户准备可用的工具。

![image-20240113100855130](https://raw.githubusercontent.com/XingYu-Zhong/LLMsStudy/master/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/pic/latm02.png)



作者提出一种调度程序，具体来说，调度程序维护工具制造商产生的现有工具的记录。当接收到新的任务实例时，调度程序最初确定手头任务是否有合适的工具。如果存在合适的工具，调度程序将实例及其对应的工具传递给工具用户进行任务解析。如果没有找到合适的工具，调度程序将实例识别为新任务，并使用强大的模型解决实例，甚至调用人类标记器。然后缓存来自新任务的实例，直到工具制造商有足够的缓存实例来制作新工具。



调度程序是一个轻量级模型，评估每个传入实例。如果已经存在合适的工具来处理任务，调度程序会选择该工具并将任务实例转发给工具用户以解析。如果没有找到合适的工具，调度程序将任务实例路由到工具制造商，以创建稍后工具用户可以使用的新工具。



有个小细节，在工具制作阶段，作者将温度设置为 0.3， 以将随机性引入生成过程，当使用工具时，作者将温度设置为0.0。对于工具暴露和工具验证阶段，最大重试次数设置为3。



## 论文实验

作者的实验部分采用了谷歌提供的bigbench数据集，一共有五份，同时作者还加了一份混合任务，加上从这五份数据集中随机抽取出来100条数据组成混合数据集，在实验上来看GPT4作为工具制造商比GPT3.5 Turbo好，同时作者提出让GPT3.5 Turbo作为工具用户的方法在几项数据集上的效果和GPT4作为工具用户相对，这也说明确实降本增效了。

![image-20240113101001961](https://raw.githubusercontent.com/XingYu-Zhong/LLMsStudy/master/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/pic/latm03.png)

Tool User对比实验

![image-20240113101029722](https://raw.githubusercontent.com/XingYu-Zhong/LLMsStudy/master/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/pic/latm04.png)

ToolMarkerModel实验



![image-20240113101100811](https://raw.githubusercontent.com/XingYu-Zhong/LLMsStudy/master/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/pic/latm05.png)

还有一点就是，作者通过实验证明使用gpt来生成prompt效果不及人类手写



## 总结

总的来说，作者提供的思想我是非常认同的，在处理一些简单任务上我们没有必要使用参数量更大的模型去做，有点像拿大炮打蚊子，完全可以想作者所提的那样去处理。